<!DOCTYPE html>
<html>
<head>
<title>RDF Dataset Normalization</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
<script type="text/javascript" src="../respec-w3c-common.js" class="remove"></script>
<script type="text/javascript" src="../respec-w3c-extensions.js" class="remove"></script>
<script type="text/javascript" class="remove">
//<![CDATA[
  var respecConfig = {
      // extend the bibliography entries
      "localBiblio": localBibliography,

      doRDFa: "1.1",
      // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
      specStatus:           "CG-DRAFT",
      //publishDate:          "2010-04-29",
      copyrightStart:       "2010",

      // the specification's short name, as in http://www.w3.org/TR/short-name/
      shortName:            "rdf-dataset-normalization",
      subtitle:             "A Standard RDF Dataset Normalization Algorithm",
      // if you wish the publication date to be other than today, set this
      // publishDate:  "2009-08-06",

      // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
      // and its maturity status
      //previousPublishDate:  "2011-08-17",
      //previousMaturity:     "ED",
      //previousDiffURI:      "http://json-ld.org/spec/ED/20110817/index.html",
      //diffTool:             "http://www.aptest.com/standards/htmldiff/htmldiff.pl",

      // if there a publicly available Editor's Draft, this is the link
      edDraftURI:           "http://json-ld.org/spec/latest/rdf-dataset-normalization/",

      // if this is a LCWD, uncomment and set the end of its review period
      // lcEnd: "2009-08-05",

      issueBase: "https://github.com/json-ld/json-ld.org/issues/",

      // if you want to have extra CSS, append them to this list
      // it is recommended that the respec.css stylesheet be kept
      // extraCSS: [],

      // editors, add as many as you like
      // only "name" is required
      editors:  [
          { name: "Dave Longley", url: "http://digitalbazaar.com/",
            company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/"},
          { name: "Manu Sporny", url: "http://manu.sporny.org/",
            company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/" }
      ],

      // authors, add as many as you like.
      // This is optional, uncomment if you have authors as well as editors.
      // only "name" is required. Same format as editors.
      authors:  [
          { name: "Dave Longley", url: "http://digitalbazaar.com/",
            company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/"}
      ],

      // name of the WG
      wg: "JSON for Linking Data W3C Community Group",

      // URI of the public WG page
      wgURI: "http://www.w3.org/community/json-ld/",

      // name (with the @w3c.org) of the public mailing to which comments are due
      wgPublicList: "public-linked-json",

      // URI of the patent status for this WG, for Rec-track documents
      // !!!! IMPORTANT !!!!
      // This is important for Rec-track documents, do not copy a patent URI from a random
      // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
      // Team Contact.
      wgPatentURI:  "",
      maxTocLevel: 2,
      preProcess: [ preProc ],
      //alternateFormats: [ {uri: "diff-20110817.html", label: "diff to previous version"} ]
  };
//]]>
</script>
<style type="text/css">
  .highlight { font-weight: bold; color: #0a3; }
  .comment { color: #999; }
  table, thead, tr, td { padding: 5px; border-width: 1px; border-spacing: 0px; border-style: solid; border-collapse: collapse; }
</style>
</head>

<body>
<section id="abstract">
  <p>RDF [[RDF-CONCEPTS]] describes a graph-based data model for making claims
    about the world and provides the foundation for reasoning upon that graph
    of information. At times, it becomes necessary to compare the differences
    between sets of graphs, digitally sign them, or generate short identifiers
    for graphs via hashing algorithms. This document outlines an algorithm for
    normalizing <tref>RDF dataset</tref>s such that these operations can be
    performed.</p>
</section>

<section id="sotd">
  <p>This document is a work in progress.</p>
  <!-- <p>This document has been reviewed by W3C Members, by software
    developers, and by other W3C groups and interested parties, and is
    endorsed by the Director as a W3C Recommendation. It is a stable
    document and may be used as reference material or cited from another
    document. W3C's role in making the Recommendation is to draw attention
    to the specification and to promote its widespread deployment. This
    enhances the functionality and interoperability of the Web.</p> -->
</section>

<section>
  <h1>Introduction</h1>

  <p>When data scientists discuss normalization, they do so in the context of
    achieving a particular set of goals. Since the same information may
    sometimes be expressed in a variety of different ways, it often becomes
    necessary to be able to transform each of these different ways into a
    single, standard format. With a standard format, the differences between
    two different sets of data can be easily determined, a
    cryptographically-strong hash identifier can be generated for a particular
    set of data, and a particular set of data may be digitally-signed for later
    verification.</p>

  <p>In particular, this specification is about normalizing
    <tref>RDF dataset</tref>s, which are collections of graphs. Since
    a directed graph can express the same information in more than one
    way, it requires normalization to achieve the aforementioned goals
    and any others that may arise via surrendipity.</p>

  <p>Most <tref>RDF dataset</tref> can be normalized fairly quickly, in terms
    of algorithmic time complexity. However, those that contain nodes that do
    not have globally unique identifiers pose a greater challenge. Normalizing
    these datasets presents the <tdef>graph isomorphism</tdef> problem, a
    problem that is believed to be difficult to solve quickly. More formally,
    it is believed to be an NP-Intermediate problem, that is, neither known to
    be solvable in polynomial time nor NP-complete. Fortunately, existing real
    world data is rarely modeled in a way that manifests this problem and new
    data can be modeled to avoid it. In fact, software systems can detect a
    problematic dataset and may choose to assume it's an attempted denial of
    service attack, rather than a real input, and abort.</p>

  <p>This document outlines an algorithm for generating a normalized
    <tref>RDF dataset</tref> given an <tref>RDF dataset</tref> as input. The
    algorithm is called the
    <strong>Universal RDF Dataset Normalization Algorithm 2015</strong> or
    <strong>URDNA2015</strong>.</p>

  <section>
    <h2>How to Read this Document</h2>

    <p>This document is a detailed specification for an <tref>RDF dataset</tref>
      normalization algorithm. The document is primarily intended for the
      following audiences:</p>

    <ul>
      <li>Software developers that want to implement an <tref>RDF dataset</tref>
        normalization algorithm.</li>
      <li>Masochists.</li>
    </ul>

    <p>To understand the basics in this specification you must be familiar with
      basic RDF concepts [[!RDF-CONCEPTS]]. A working knowledge of
      <a href="http://en.wikipedia.org/wiki/Graph_theory">graph theory</a> and
      <a href="http://en.wikipedia.org/wiki/Graph_isomorphism">graph isomorphism</a>
      is also recommended.</p>
  </section>

  <section>
    <h2>Contributing</h2>

    <p>There are a number of ways that one may participate in the development
      of this specification:</p>

    <ul>
      <li>Technical discussion typically occurs on the public mailing list:
        <a href="http://lists.w3.org/Archives/Public/public-linked-json/">public-linked-json@w3.org</a></li>

      <li><a href="http://json-ld.org/minutes/">Public teleconferences</a> are
        held on Tuesdays at 1500UTC on the second and fourth week of each
        month.</li>

      <li>Specification bugs and issues should be reported in the
        <a href="https://github.com/json-ld/json-ld.org/issues">issue tracker</a>.</li>

      <li><a href="https://github.com/json-ld/json-ld.org/tree/master/spec">Source code</a> for the
        specification can be found on Github.</li>

      <li>The <a href="http://webchat.freenode.net/?channels=#json-ld">#json-ld</a>
        IRC channel is available for real-time discussion on
        <a href="irc.freenode.net">irc.freenode.net.</a></li>
    </ul>
  </section>
</section>

<section class="normative">
  <h1>Terminology</h1>

  <section class="normative">
    <h2>General Terminology</h2>

    <dl>
      <dt><tdef>string</tdef></dt><dd>
        A string is a sequence of zero or more Unicode characters.</dd>
      <dt><tdef>true</tdef> and <tdef>false</tdef></dt><dd>
        Values that are used to express one of two possible boolean states.</dd>
      <dt><tdef><abbr title="Internationalized Resource Identifier">IRI</abbr></tdef></dt>
      <dd>An <tref>IRI</tref> (Internationalized Resource Identifier) is a string that conforms to the syntax
        defined in [[RFC3987]].</dd>
      <dt><tdef>RDF subject</tdef></dt>
      <dd>A <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-subject">subject</tref>
        as specified by [[RDF11-CONCEPTS]].</dd>
      <dt><tdef>RDF predicate</tdef></dt>
      <dd>A <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-predicate">predicate</tref>
        as specified by [[RDF11-CONCEPTS]].</dd>
      <dt><tdef>RDF object</tdef></dt>
      <dd>An <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-object">object</tref>
        as specified by [[RDF11-CONCEPTS]].</dd>
      <dt><tdef>RDF triple</tdef></dt>
      <dd>A <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-rdf-triple">triple</tref>
        as specified by [[RDF11-CONCEPTS]].</dd>
      <dt><tdef>RDF graph</tdef></dt>
      <dd>An <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-rdf-graph">RDF graph</tref>
        as specified by [[RDF11-CONCEPTS]].</dd>
      <dt><tdef>RDF graph name</tdef></dt>
      <dd>A <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-rdf-dataset">graph name</tref>
        as specified by [[RDF11-CONCEPTS]].</dd>
      <dt><tdef>RDF quad</tdef></dt>
      <dd>The pairing of an <tref>RDF triple</tref> with an <tref>RDF graph name</tref>.</dd>
      <dt><tdef>RDF dataset</tdef></dt>
      <dd>A <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-rdf-dataset">dataset</tref>
        as specified by [[RDF11-CONCEPTS]].</dd>
      <dt><tdef>RDF blank node</tdef></dt>
      <dd>A <tref href="http://www.w3.org/TR/rdf11-concepts/#section-blank-nodes">blank node</tref>
        as specified by [[RDF11-CONCEPTS]]. In short, it is a node in a graph that is
        neither an <tref>IRI</tref>, nor a
        <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-literal">literal</tref>.</dd>
      <dt><tdef>RDF blank node identifier</tdef></dt>
      <dd>A <tref href="http://www.w3.org/TR/rdf11-concepts/#dfn-blank-node-identifier">blank node identifier</tref>
        as specified by [[RDF11-CONCEPTS]]. In short, it is a string that begins
        with <code>_:</code> that is used as an identifier for an
        <tref>RDF blank node</tref>. <tref>RDF blank node identifier</tref>s
        are typically implementation-specific local identifiers; this document
        specifies an algorithm for deterministically specifying them.</dd>
    </dl>
  </section>
</section>

<section>
  <h1>Normalization</h1>

  <p>Normalization is the process of transforming an
    <tref>input RDF dataset</tref> to a <tref>normalized RDF dataset</tref>. That
    is, any two <tref>input RDF dataset</tref>s that contain the same
    information, regardless of their arrangement, will be transformed into
    identical <tref>normalized RDF dataset</tref>s. The problem requires directed
    graphs to be deterministically ordered into sets of nodes and edges. This
    is easy to do when all of the nodes have globally-unique identifiers, but
    can be difficult to do when some of the nodes do not. Any nodes without
    globally-unique identifiers must be issued deteriministic identifiers.</p>

  <p>In time, there may be more than one normalization algorithm and,
    therefore, for identification purposes, this algorithm is named the
    "Universal RDF Dataset Normalization Algorithm 2015"
    (<abbr title="Universal RDF Dataset Normalization Algorithm 2015">URDNA2015</abbr>).</p>

  <section>
    <h1>Normalization Algorithm Terms</h1>
    <dl>
      <dt><tdef>input RDF dataset</tdef></dt>
      <dd>The abstract <tref>RDF dataset</tref> that is provided as input to
        the algorithm.</dd>
      <dt><tdef>normalized RDF dataset</tdef></dt>
      <dd>The abstract <tref>RDF dataset</tref> and normalized
        <tref>RDF blank node identifier</tref>s that are produced as output by
        the algorithm.</dd>
      <dt><tdef>identifier issuer</tdef></dt>
      <dd>An identifier issuer is used to issue new <tref>RDF blank node identifier</tref>s. It
        maintains a
        <a href="#blank-node-identifier-issuer-state">blank node identifier issuer state</a>.</dd>
      <dt><tdef>hash</tdef></dt>
      <dd>The lowercase, hexadecimal representation of a message digest.</dd>
      <dt><tdef>hash algorithm</tdef></dt>
      <dd>The hash algorithm used by URDNA2015, namely, SHA-256.</dd>
    </dl>
  </section>

  <section>
    <h1>Normalization State</h1>

    <p>When performing the steps required by the normalization algorithm,
      it is helpful to track state in a data structure called the
      <tdef>normalization state</tdef>. The information contained in the
      <tref>normalization state</tref> is described below.</p>

    <dl>
      <dt><tdef>blank node to quads map</tdef></dt>
      <dd>A data structure that maps <tref>RDF blank node identifier</tref>s to
        the <tref>RDF quad</tref>s in which they appear in the
        <tref>input RDF dataset</tref>.</dd>
      <dt><tdef>hash to blank nodes map</tdef></dt>
      <dd>A data structure that maps a <tref>hash</tref> to a list of
        <tref>RDF blank node identifier</tref>s.</dd>
      <dt><tdef>canonical issuer</tdef></dt>
      <dd>An <tref>identifier issuer</tref>, initialized with the
        prefix <code>_:c14n</code>, for issuing canonical
        <tref>RDF blank node identifier</tref>s.
      </dd>
    </dl>
  </section>

  <section>
    <h1>Blank Node Identifier Issuer State</h1>

    <p>During the normalization algorithm, it is sometimes necessary to
      issue new identifiers to <tref>RDF blank node</tref>s. The
      <a href="#issue-identifier-algorithm">Issue Identifier algorithm</a> uses an
      <tref>identifier issuer</tref> to accomplish this task. The information
      an <tref>identifier issuer</tref> needs to keep track of is described
      below.</p>

    <dl>
      <dt><tdef>identifier prefix</tdef></dt>
      <dd>The identifier prefix is a string that is used at the beginning of an
        <tref>RDF blank node identifier</tref>. It should be initialized to a
        string that is specified by the normalization algorithm. When
        generating a new <tref>RDF blank node identifier</tref>, the prefix
        is concatenated with a <tref>identifier counter</tref>. For example,
        <code>_:c14n</code> is a proper initial value for the
        <tref>identifier prefix</tref> that would produce
        <tref>RDF blank node identifier</tref>s like <code>_:c14n1</code>.</dd>
      <dt><tdef>identifier counter</tdef></dt>
      <dd>A counter that is appended to the <tref>identifier prefix</tref> to
        create an <tref>RDF blank node identifier</tref>. It is initialized to
        <code>0</code>.</dd>
      <dt><tdef>issued identifiers list</tdef></dt>
      <dd>A list that tracks previously issued identifiers in the order in
        which they were issued. It also tracks the existing identifier that
        triggered the issuance, to prevent issuing more than one new identifier
        per existing identifier, and to allow <tref>RDF blank node</tref>s to
        be reassigned identifiers some time after issuance.</dd>
    </dl>
  </section>

  <section>
    <h2>Normalization Algorithm</h2>

    <p>The normalization algorithm converts an <tref>input RDF dataset</tref>
      into a <tref>normalized RDF dataset</tref>. This algorithm will assign
      deterministic identifiers to any <tref>RDF blank node</tref>s in the
      <tref>input RDF dataset</tref>.</p>

    <p class="issue">Documenting the algorithm is a WIP, various steps will
      become more detailed in time.</p>

    <section class="informative">
      <h3>Overview</h3>
    </section>

    <section>
      <h3>Algorithm</h3>

      <ol class="algorithm">
        <li>Create the <tref>normalization state</tref>.</li>
        <li>For every <tref>RDF quad</tref> in <tref>input RDF dataset</tref>:
          <ol class="algorithm">
            <li>For each <tref>RDF blank node</tref> that occurs in the
              <tref>RDF quad</tref>, add a reference to the
              <tref>RDF quad</tref> using the
              <tref>RDF blank node identifier</tref> in the
              <tref>blank node to quads map</tref>, creating a new entry if
              necessary.
            </li>
          </ol>
        </li>
        <li>Create a list of non-normalized <tref>blank node identifier</tref>s
          <i>non-normalized identifiers</i> and populate it using the keys
          from the <tref>blank node to quads map</tref>.</li>
        <li>Initialize <i>simple</i>, a boolean flag, to
          <code>true</code>.</li>
        <li>While <i>simple</i> is <code>true</code>,
          issue canonical identifiers for <tref>RDF blank node</tref>s:</li>
          <ol class="algorithm">
            <li>Set <i>simple</i> to <code>false</code>.</li>
            <li>Clear <tref>hash to blank nodes map</tref>.</li>
            <li>For each <tref>RDF blank node identifier</tref>
              <i>identifier</i> in <i>non-normalized identifiers</i>:</li>
              <ol class="algorithm">
                <li>Create a <tref>hash</tref>, <i>hash</i>, according to the
                  <a href="#hash-first-degree-quads">Hash First Degree Quads algorithm</a>.</li>
                <li>Add <i>hash</i> and <i>identifier</i> to
                  <tref>hash to blank nodes map</tref>, creating a new entry if
                  necessary.</li>
              </ol>
            <li>For each <i>hash</i> to <i>identifier list</i> mapping in
              <tref>hash to blank nodes map</tref>, lexicographically-sorted by
              <i>hash</i>:
              <ol class="algorithm">
                <li>If the length of <i>identifier list</i> is greater than
                  <code>1</code>, continue to the next mapping.</li>
                <li>Use the
                  <a href="#issue-identifier">Issue Identifier algorithm</a>,
                  passing <tref>canonical issuer</tref> and the
                  single <tref>RDF blank node identifier</tref> in
                  <i>identifier list</i>, <i>identifier</i>, to issue a
                  canonical replacment identifier for <i>identifier</i>.</li>
                <li>Remove <i>identifier</i> from
                  <i>non-normalized identifiers</i>.</li>
                <li>Remove <i>hash</i> from the
                  <tref>hash to blank nodes map</tref>.</li>
                <li>Set <i>simple</i> to <code>true</code>.</li>
              </ol>
            </li>
          </ol>
        </li>
        <li>For each <i>hash</i> to <i>identifier list</i> mapping in
          <tref>hash to blank nodes map</tref>, lexicographically-sorted by
          <i>hash</i>:
          <ol class="algorithm">
            <li>Create <i>hash path list</i> where each item will be a result
              of running the
              <a href="#hash-n-degree-quads">Hash N-Degree Quads algorithm</a>.</li>
            <li>For each <tref>RDF blank node identifier</tref>
              <i>identifier</i> in <i>identifier list</i>:</li>
              <ol class="algorithm">
                <li>If a canonical identifier has already been issued for
                  <i>identifier</i>, continue to the next
                  <i>identifier</i>.</li>
                <li>Create <i>temporary issuer</i>, an
                  <tref>identifier issuer</tref> initialized with the prefix
                  <code>_:b</code>.</li>
                <li>Use the
                  <a href="#issue-identifier">Issue Identifier algorithm</a>,
                  passing <i>temporary issuer</i> and <i>identifier</i>, to
                  issue a new temporary <tref>RDF blank node identifier</tref>
                  for <i>identifier</i>.</li>
                <li>Run the
                  <a href="#hash-n-degree-quads">Hash N-Degree Quads algorithm</a>,
                  passing <i>temporary issuer</i>, and append the
                  result to the <i>hash path list</i>.</li>
              </ol>
            </li>
            <li>For each <i>result</i> in the <i>hash path list</i>,
              lexicographically-sorted by the <i>hash</i> in <i>result</i>:</li>
              <ol class="algorithm">
                <li>For each <tref>RDF blank node identifier</tref>,
                  <i>existing identifier</i>, that was issued a temporary
                  identifier by <i>identifier issuer</i> in <i>result</i>, issue
                  a canonical identifier, in the same order, using the
                  <a href="#issue-identifier">Issue Identifier algorithm</a>,
                  passing <tref>canonical issuer</tref> and
                  <i>existing identifier</i>.
              </ol>
            </li>
          </ol>
        </li>
        <li>For each <tref>RDF quad</tref>, <i>quad</i>, in
          <tref>input RDF dataset</tref>:
          <ol class="algorithm">
            <li>Create a copy, <i>quad copy</i>, of <i>quad</i> and replace any
              existing <tref>RDF blank node identifier</tref>s using the
              canonical identifiers previously issued
              by <tref>canonical issuer</tref>.</li>
            <li>Add <i>quad copy</i> to the
              <tref>normalized RDF dataset</tref>.</li>
          </ol>
        </li>
        <li>Return the <tref>normalized RDF dataset</tref>.</li>
      </ol>
    </section>
  </section>

  <section>
    <h2>Issue Identifier Algorithm</h2>

    <section class="informative">
      <h3>Overview</h3>
    </section>

    <section>
      <h3>Algorithm</h3>
    </section>

    <p>This algorithm issues a new <tref>RDF blank node identifier</tref> for
      a given existing <tref>RDF blank node identifier</tref>. It also updates
      state information that tracks the order in which new
      <tref>RDF blank node identifier</tref>s were issued.</p>

    <p>This algorithm takes an <tref>identifier issuer</tref> and an
      <i>existing identifier</i> as inputs. The output is a new
      <i>issued identifier</i>. The steps of the algorithm are:</p>

    <ol class="algorithm">
      <li>If there is already an issued identifier for
        <i>existing identifier</i> in <tref>issued identifiers list</tref>,
        return it.</li>
      <li>Generate <i>issued identifier</i> by concatenating
        <tref>identifier prefix</tref> with the string value of
        <tref>identifier counter</tref>.</li>
      <li>Append an item to <tref>issued identifiers list</tref> that maps
        <i>existing identifier</i> to <i>issued identifier</i>.</li>
      <li>Increment <tref>identifier counter</tref>.</li>
      <li>Return <i>issued identifier</i>.</li>
    </ol>
  </section>

  <section>
    <h2>Hash First Degree Quads</h2>

    <p class="issue">Add note that it is safe to cache the result of
      hashing the quads for later reuse (to reduce unnecessary computation).</p>

    <section class="informative">
      <h3>Overview</h3>
    </section>

    <section>
      <h3>Algorithm</h3>

      <p>This algorithm takes the <tref>normalization state</tref> and a
        <tdef>reference blank node identifier</tdef> as inputs.</p>

      <ol class="algorithm">
        <li>Initialize <tdef>nquads</tdef> to an empty list. It will be
          used to store quads in N-Quads format.</li>
        <li>Get the list of quads <i>quads</i> associated with the
          <tref>reference blank node identifier</tref> in the
          <tref>blank node to quads map</tref>.</li>
        <li>For each <tref>RDF quad</tref> <i>quad</i> in <i>quads</i>:
          <ol class="algorithm">
            <li>Serialize the <tref>RDF quad</tref> in N-Quads format with the
              following special rule:
              <ol class="algorithm">
                <li>If any component in <i>quad</i> is an
                  <tref>RDF blank node</tref>, then serialize it using a
                  special identifier as follows:
                  <ol class="algorithm">
                    <li>If the <tref>blank node</tref>'s existing
                    <tref>RDF blank node identifier</tref> matches the
                    <tref>reference blank node identifier</tref> then use the
                    <tref>RDF blank node identifier</tref> <code>_:a</code>,
                    otherwise, use the <tref>RDF blank node identifier</tref>
                    <code>_:z</code>.</li>
                  </ol>
                </li>
              </ol>
            </li>
          </ol>
        </li>
        <li>Sort <tref>nquads</tref> in lexicographical order.</li>
        <li>Return the <tref>hash</tref> that results from passing the sorted,
          joined <tref>nquads</tref> through the
          <tref>hash algorithm</tref>.</li>
      </ol>
    </section>
  </section>

  <section>
    <h2>Hash Related Blank Node</h2>

    <section class="informative">
      <h3>Overview</h3>
    </section>

    <section>
      <h3>Algorithm</h3>

      <p>This algorithm creates a <tref>hash</tref> to identify how one
        <tref>RDF blank node</tref> is related to another. It takes the
        <tref>normalization state</tref>, a <i>related</i>
        <tref>RDF blank node identifier</tref>, a <i>quad</i>, an
        <tref>identifier issuer</tref>, <i>issuer</i>, and a
        <tref>string</tref> <i>position</i> as inputs.</p>

      <ol class="algorithm">
        <li>Set the <i>identifier</i> to use for <i>related</i>, preferring
          first the canonical identifier for <i>related</i> if issued, second
          the identifier issued by <i>issuer</i> if issued, and last, if
          necessary, the result of the
          <a href="#hash-first-degree-quads">Hash First Degree Quads algorithm</a>,
          passing <i>related</i>.
        </li>
        <li>Initialize a <tref>string</tref> <i>input</i> to the value of
          <i>position</i>.</li>
        <li>If <i>position</i> is not <code>g</code>, append
          <code>&lt;</code>, the value of the <tref>RDF predicate</tref> in
          <i>quad</i>, and <code>&gt;</code> to <i>input</i>.</li>
        <li>Append <i>identifier</i> to <i>input</i>.</li>
        <li>Return the <tref>hash</tref> that results from passing <i>input</i>
          through the <tref>hash algorithm</tref>.</li>
      </ol>
    </section>
  </section>

  <section>
    <h2>Hash N-Degree Quads</h2>

    <p class="issue">The relationship and difference between this algorithm
      and the hash first degree quads algorithm should be better explained.
      There may also be better names for the two algorithms.</p>

    <p class="issue">The 'path' terminology could also be changed to better
      indicate what a path is (a particular deterministic serialization for
      a subgraph/subdataset of nodes without globally-unique identifiers).</p>

    <section class="informative">
      <h3>Overview</h3>

      <p>Usually, when trying to determine if two nodes in a graph are
        equivalent, you simply compare their identifiers. However, what if the
        nodes don't have identifiers? Then you must determine if the two nodes
        have equivalent connections to equivalent nodes all throughout the
        whole graph. This is called the graph isomorphism problem. This
        algorithm approaches this problem by considering how one might draw
        a graph on paper. You can test to see if two nodes are equivalent
        by drawing the graph twice. The first time you draw the graph the
        first node is drawn in the center of the page. If you can draw the
        graph a second time such that it looks just like the first, except
        the second node is in the center of the page, then the nodes are
        equivalent. This algorithm essentially defines a determinitsic way to
        draw a graph where, if you begin with a particular node, the graph
        will always be drawn the same way. If two graphs are drawn the same way
        with two different nodes, then the nodes are equivalent. A
        <tref>hash</tref> is used to indicate a particular way that the graph
        has been drawn and can be used to compare nodes.</p>

      <p>This algorithm works in concert with the main normalization algorithm
        to produce a unique, deterministic identifier for a particular blank
        node. This <tref>hash</tref> incorporates all of the information that
        is connected to the blank node as well as how it is connected. It does
        this by creating deterministic paths that emanate out from the blank
        node through any other adjacent blank nodes.</p>
    </section>

    <section>
      <h3>Algorithm</h3>

      <p>The inputs to this algorithm are the <tref>normalization state</tref>,
        the <i>identifier</i> for the <tref>RDF blank node</tref> to
        recursively hash quads for, and path identifier <i>issuer</i> which is
        an <tref>identifier issuer</tref> that issues temporary
        <tref>RDF blank node identifier</tref>s. The output from this algorithm
        will be a <tref>hash</tref> and the <tref>identifier issuer</tref> used
        to help generate it.</p>

    <p class="issue">In URGNA2012, the <i>position</i> parameter passed to
      the <a href="#hash-related-blank-node">Hash Related Blank Node algorithm</a>
      was instead modeled as a <i>direction</i> parameter, where it could have
      the value <code>p</code>, for property, when the related blank node was a
      `subject` and the value <code>r</code>, for reverse or reference, when
      the related blank node was an `object`. Since URGNA2012 only normalized
      graphs, not datasets, there was no use of the `graph` position.</p>

      <ol class="algorithm">
        <li>Create an <i>hash to related blank nodes map</i> for storing
          hashes that identify related <tref>RDF blank node</tref>s.</li>
        <li>Get a reference, <i>quads</i>, to the list of <tref>RDF quad</tref>s
          in the <tref>blank node to quads map</tref> for the key
          <i>identifier</i>.</li>
        <li>For each <i>quad</i> in <i>quads</i>:
          <ol class="algorithm">
            <li>For each <i>component</i> in <i>quad</i>, if <i>component</i>
              is the <tref>RDF subject</tref>, <tref>RDF object</tref>, and
              <tref>RDF graph name</tref> and it is an
              <tref>RDF blank node</tref> that is not identified by
              <i>identifier</i>:
              <ol class="algorithm">
                <li>Set <i>hash</i> to the result of the
                  <a href="#hash-related-blank-node">Hash Related Blank Node algorithm</a>,
                  passing the <tref>RDF blank node identifier</tref> for
                  <i>component</i> as <i>related</i>, <i>quad</i>,
                  <i>path identifier issuer</i> as <i>issuer</i>, and
                  <i>position</i> as either <code>s</code>, <code>o</code>, or
                  <code>g</code> based on whether <i>component</i> is an
                  <tref>RDF subject</tref>, <tref>RDF object</tref>,
                  <tref>RDF graph name</tref>, respectively.</li>
                <li>Add a mapping of <i>hash</i> to the
                  <tref>RDF blank node identifier</tref> for <i>component</i>
                  <i>hash to related blank nodes map</i>, adding an entry
                  as necessary.</li>
              </ol>
            </li>
          </ol>
        </li>
        <li>Create an empty string, <i>data to hash</i>.</li>
        <li>For each <i>related hash</i> to <i>blank node list</i> mapping in
          <i>hash to related blank nodes map</i>, sorted lexicographically
          by <i>related hash</i>:
          <ol class="algorithm">
            <li>Append the <i>related hash</i> to the <i>data to hash</i>.</li>
            <li>Create a <tref>string</tref> <i>chosen path</i>.</li>
            <li>Create an unset <i>chosen issuer</i> variable.</li>
            <li>For each <i>permutation</i> of <i>blank node list</i>:
              <ol class="algorithm">
                <li>Create a copy of <i>issuer</i>, <i>issuer copy</i>.</li>
                <li>Create a <tref>string</tref> <i>path</i>.</li>
                <li>Create a <i>recursion list</i>, to store
                  <tref>RDF blank node identifier</tref>s that must be
                  recursively processed by this algorithm.</li>
                <li>For each <i>related</i> in <i>permutation</i>:
                  <ol class="algorithm">
                    <li>If a canonical identifier has been issued for
                      <i>related</i>, append it to <i>path</i>.</li>
                    <li>Otherwise, if <i>issuer copy</i> has not issued
                      an identifier for <i>related</i>, append <i>related</i>
                      to <i>recursion list</i>. Use the
                      <a href="#issue-identifier">Issue Identifier algorithm</a>,
                      passing <i>issuer copy</i> and <i>related</i> and
                      append the result to <i>path</i>.
                    </li>
                    <li>If <i>chosen path</i> is not empty and the length
                      of <i>path</i> is greater than or equal to the length
                      of <i>chosen path</i> and <i>path</i> is lexicographically
                      greater than <i>chosen path</i>, then skip to the next
                      <i>permutation</i>.
                    </li>
                  </ol>
                </li>
                <li>For each <i>related</i> in <i>recursion list</i>:
                  <ol class="algorithm">
                    <li>Set <i>result</i> to the result of recursively executing
                      the
                      <a href="#hash-n-degree-quads">Hash N-Degree Quads algorithm</a>,
                      passing <i>related</i> for <i>identifier</i> and
                      <i>issuer copy</i> for <i>path identifier issuer</i>.</li>
                    <li>Use the
                      <a href="#issue-identifier">Issue Identifier algorithm</a>,
                      passing <i>issuer copy</i> and <i>related</i> and
                      append the result to <i>path</i>.</li>
                    <li>Append <code>&lt;</code>, the <tref>hash</tref> in
                      <i>result</i>, and <code>&gt;</code> to <i>path</i>.</li>
                    <li>Set <i>issuer copy</i> to the
                      <tref>identifier issuer</tref> in result.</li>
                    <li>If <i>chosen path</i> is not empty and the length
                      of <i>path</i> is greater than or equal to the length
                      of <i>chosen path</i> and <i>path</i> is lexicographically
                      greater than <i>chosen path</i>, then skip to the next
                      <i>permutation</i>.</li>
                  </ol>
                </li>
                <li>If <i>chosen path</i> is empty or <i>path</i> is
                  lexicographically less than <i>chosen path</i>, set
                  <i>chosen path</i> to <i>path</i> and <i>chosen issuer</i>
                  to <i>issuer copy</i>.</li>
              </ol>
            </li>
            <li>Append <i>chosen path</i> to <i>data to hash</i>.</li>
            <li>Replace <i>issuer</i>, by reference, with
              <i>chosen issuer</i>.</li>
          </ol>
        </li>
        <li>Return <i>issuer</i> and the <tref>hash</tref> that results from
          passing <i>data to hash</i> through the
          <tref>hash algorithm</tref>.</li>
      </ol>
    </section>
  </section>
</section>

<section class="appendix">
  <h1>Acknowledgements</h1>

  <p>The editors would like to thank Jeremy Carroll for his work on the
    graph normalization problem, Gavin Carothers for providing valuable
    feedback and testing input for the algorithm defined in this
    specification, Sir Tim Berners Lee for his thoughts on graph normalization
    over the years, Jesús Arias Fisteus for his work on a similar
    algorithm.</p>
</section>

</body>
</html>
